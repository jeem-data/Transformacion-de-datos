{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "from pypdf import PdfReader \n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import logging\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "json_path = os.getenv('json_path') # Variable donde se encuentra la ruta del json con las credenciales de Google Cloud\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = json_path \n",
    "logging.basicConfig(filename='error_log.txt', level=logging.ERROR, format='%(asctime)s %(message)s')\n",
    "bucket_name = 'tfm_javi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que se encarga de devolver un PDF dado su nombre y el bucket donde está almacenado\n",
    "def leer_blob_en_memoria(bucket_name, blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    pdf_content = blob.download_as_bytes()\n",
    "    return pdf_content\n",
    "\n",
    "# Función que transforma un pdf en una cadena de texto que puede ser procesada\n",
    "def extraer_texto_de_pdf_bytes(pdf_bytes):\n",
    "    pdf_file = BytesIO(pdf_bytes)\n",
    "    reader = PdfReader(pdf_file)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + '\\n'\n",
    "    return text\n",
    "\n",
    "# Función que combina las dos funciones creadas anteriormente en una sola\n",
    "def procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name):\n",
    "    pdf_bytes = leer_blob_en_memoria(bucket_name, blob_name)\n",
    "    content = extraer_texto_de_pdf_bytes(pdf_bytes)\n",
    "    return content\n",
    "\n",
    "# Función que se encarga de devolver una lista con todos los nombres de los archivos en un bucket\n",
    "def listar_pdfs(bucket_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs()\n",
    "\n",
    "    # Filtra los archivos PDF y guarda sus URLs completas en la lista\n",
    "    listado_pdfs = [f\"gs://{bucket_name}/{blob.name}\" for blob in blobs if blob.name.endswith('.pdf') and not blob.name.startswith('resoluciones/')]\n",
    "    return listado_pdfs\n",
    "\n",
    "# Función que se encarga de dividir la lista de todos los PDFs en 5 partes para facilitar su procesado en tandas\n",
    "def dividir_lista_pdfs(listado_pdfs):\n",
    "    total = len(listado_pdfs)\n",
    "    tamaño_parte = total // 5\n",
    "    \n",
    "    parte1 = listado_pdfs[:tamaño_parte]\n",
    "    parte2 = listado_pdfs[tamaño_parte:2*tamaño_parte]\n",
    "    parte3 = listado_pdfs[2*tamaño_parte:3*tamaño_parte]\n",
    "    parte4 = listado_pdfs[3*tamaño_parte:4*tamaño_parte]\n",
    "    parte5 = listado_pdfs[4*tamaño_parte:]\n",
    "    \n",
    "    return parte1, parte2, parte3, parte4, parte5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición los esquemas de respuesta\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"numero_expediente\", description=\"Número de Expediente, ejemplo SD2023/0000046\"),\n",
    "    ResponseSchema(name=\"resolucion\", description=\"Una de las siguientes opciones: negada_con_oposicion, negada_sin_oposicion, aprobada_sin_oposicion, aprobada_con_oposición\"),\n",
    "    ResponseSchema(name=\"numero_de_resolución\", description=\"Número entero de la resolución, ejemplo 2195\"),\n",
    "    ResponseSchema(name=\"denominacion\", description=\"Nombre de la empresa que solicita el registro de la marca\"),\n",
    "    ResponseSchema(name=\"vigencia\", description=\"Fecha en que expira la vigencia del registro, o texto si es negada o vencida\"),\n",
    "    ResponseSchema(name=\"titular\", description=\"Titular de la marca que intenta registrar\"),\n",
    "    ResponseSchema(name=\"clase\", description=\"Número o lista de números de la Clasificación Internacional de Niza, por ejemplo [42, 35, 27]\"),\n",
    "    ResponseSchema(name=\"gaceta\", description=\"Número de la gaceta de Propiedad Industrial donde se publica\"),\n",
    "    ResponseSchema(name=\"tipo\", description=\"Tipo de registro que se intenta realizar, por ejemplo Mixta, Nominativa, Figurativa\"),\n",
    "    ResponseSchema(name=\"fecha_solicitud\", description=\"Fecha de presentación de la solicitud\"),\n",
    "    ResponseSchema(name=\"fecha_resolucion\", description=\"Fecha de resolución\"),\n",
    "    ResponseSchema(name=\"nombre_opositor\", description=\"Nombre de la empresa que se opone a la publicación\"),\n",
    "    ResponseSchema(name=\"signo_opositor_opositores\", description=\"Signo o signos de los opositores en conflicto\"),\n",
    "    ResponseSchema(name=\"argumento_oposición\", description=\"Argumentos en los que se basa para oponerse al registro y artículos en los que se apoya\"),\n",
    "    ResponseSchema(name=\"explicacion_argumentos_oposicion\", description=\"Breve resumen y explicación de los argumentos de la oposición\"),\n",
    "    ResponseSchema(name=\"resolucion_organismo\", description=\"Resolución del organismo competente, por ejemplo: 'DENIEGA el registro de la marca PAPELES LA FAVORITA (Mixta)'\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "# Escapar las llaves para evitar la interpretación de variables\n",
    "format_instructions = format_instructions.replace(\"{\", \"{{\").replace(\"}\", \"}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de los prompts que se le van a pasar a VertexAI para darle instrucciones de qué hacer\n",
    "system_prompt = \"\"\"\n",
    "Eres un Experto abogado Colombiano en analizar resoluciones del SIC (Superintendencia de Industria y Comercio de Colombia),en el ámbito de registro de marcas y lemas.\n",
    "quiero que extraigas el numero de Expediente, la resolución del conflicto, el numero de la resolución, el nombre de la marca que intenta registrarse, el titular que intenta registrar la marca, el numero de clase que intenta registrar, \n",
    "el numero de la gaceta en que ha sido publicada, la fecha de solicitud de registro, nombre de la empresa opositora, el titular de la empresa que se opone si aparece, y los argumentos de derecho en los que se apoya el opositor.\n",
    "\"\"\"\n",
    "human_prompt = f\"\"\"Extrae la información indicada en DATOS a partir del TEXTO de la resolución\n",
    "\n",
    "TEXT\n",
    "---\n",
    "\\n\\n{{contenido_pdf}}\n",
    "---\n",
    "\n",
    "DATOS\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    HumanMessagePromptTemplate.from_template(human_prompt),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tu LLM \n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.5-pro-001\" \n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, output_parser=output_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la lista de PDFs\n",
    "listado_pdfs = listar_pdfs(bucket_name)\n",
    "\n",
    "# Comprobamos la longitud total de los PDFs en el bucket\n",
    "len(listado_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos la lista de PDFs en 5 partes para facilitar su procesado (procesar tantos PDFs lleva tiempo y procesar 12000-13000 PDFs implicaria demasiado tiempo)\n",
    "parte1, parte2, parte3, parte4, parte5 = dividir_lista_pdfs(listado_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar una lista para almacenar los resultados y los errores\n",
    "resultados = []\n",
    "listado_pdfs_error = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "\n",
    "A continuación se va a proceder a transformar todos los PDFs de la parte 1 en datos que puedan ser explotados mas adelante. Durante el procesado de estos PDFs a veces se pueden dar errores, por lo que guardamos los nombres de los archivos que han dado error para poder procesarlos de nuevo mas adelante. Una vez se haya concluido de procesar la parte 1, se hará lo mismo con el resto de las partes (2, 3, 4, y 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos todos los PDFs de la primera parte\n",
    "for pdf_uri in parte1:\n",
    "    blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "    contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "    # Verificar si el contenido del PDF no está vacío\n",
    "    if contenido_pdf.strip():\n",
    "        try:\n",
    "            # Invocar la cadena con el contenido del PDF\n",
    "            res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "            #Agregar el resultado a la lista de resultados\n",
    "            resultados.append(res)\n",
    "            #Imprimir el resultado\n",
    "            print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "        except Exception as e:\n",
    "            # Si hay algún error al procesar el archivo (a veces pasa), guardamos su nombre para intentarlo otra vez mas adelante\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            listado_pdfs_error.append(blob_name)\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "    else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores de analisis de la parte 1\n",
    "\n",
    "Todos los PDFs que dieron error al ser procesados en la sección anterior se han fuardado en una variable llamada listado_pdfs_error. Para procesar esta parte procedemos a llamar a la misma función que en el apartado anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos la longitud de la lista con los PDFs que han dado error al ser procesados\n",
    "print(listado_pdfs_error)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos la lista de nuevo procesando los PDFs una segunda vez\n",
    "for pdf_uri in listado_pdfs_error:\n",
    "     blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "     contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "      # Verificar si el contenido del PDF no está vacío\n",
    "     if contenido_pdf.strip():\n",
    "         try:\n",
    "              # Invocar la cadena con el contenido del PDF\n",
    "             res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "              #Agregar el resultado a la lista de resultados\n",
    "             resultados.append(res)\n",
    "              #Imprimir el resultado\n",
    "             print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "         except Exception as e:\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "     else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_annotations_full_1 = pd.DataFrame.from_records(df_resultados['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_annotations_full_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos cuantas files tienen entradas en blanco y el tipo de variable de cada columna\n",
    "df_ai_annotations_full_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los resultados en un archivo csv\n",
    "df_ai_annotations_full_1.to_csv(\"datasetia_full_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a realizar los mismo pasos para las partes 2, 3, 4, y 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciamos las listas\n",
    "resultados = []\n",
    "listado_pdfs_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos todos los PDFs de la segunda parte\n",
    "for pdf_uri in parte2:\n",
    "    blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "    contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "    # Verificar si el contenido del PDF no está vacío\n",
    "    if contenido_pdf.strip():\n",
    "        try:\n",
    "            # Invocar la cadena con el contenido del PDF\n",
    "            res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "            #Agregar el resultado a la lista de resultados\n",
    "            resultados.append(res)\n",
    "            #Imprimir el resultado\n",
    "            print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "        except Exception as e:\n",
    "            # Si hay algún error al procesar el archivo (a veces pasa), guardamos su nombre para intentarlo otra vez mas adelante\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            listado_pdfs_error.append(blob_name)\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "    else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores de analisis de la parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos la longitud de la lista con los PDFs que han dado error al ser procesados\n",
    "print(listado_pdfs_error)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos la lista de nuevo procesando los PDFs una segunda vez\n",
    "for pdf_uri in listado_pdfs_error:\n",
    "     blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "     contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "      # Verificar si el contenido del PDF no está vacío\n",
    "     if contenido_pdf.strip():\n",
    "         try:\n",
    "              # Invocar la cadena con el contenido del PDF\n",
    "             res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "              #Agregar el resultado a la lista de resultados\n",
    "             resultados.append(res)\n",
    "              #Imprimir el resultado\n",
    "             print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "         except Exception as e:\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "     else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_ai_annotations_full_2 = pd.DataFrame.from_records(df_resultados['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos cuantas files tienen entradas en blanco y el tipo de variable de cada columna\n",
    "df_ai_annotations_full_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los resultados en un archivo csv\n",
    "df_ai_annotations_full_2.to_csv(\"datasetia_full_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciamos las listas\n",
    "resultados = []\n",
    "listado_pdfs_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos todos los PDFs de la segunda parte\n",
    "for pdf_uri in parte3:\n",
    "    blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "    contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "    # Verificar si el contenido del PDF no está vacío\n",
    "    if contenido_pdf.strip():\n",
    "        try:\n",
    "            # Invocar la cadena con el contenido del PDF\n",
    "            res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "            #Agregar el resultado a la lista de resultados\n",
    "            resultados.append(res)\n",
    "            #Imprimir el resultado\n",
    "            print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "        except Exception as e:\n",
    "            # Si hay algún error al procesar el archivo (a veces pasa), guardamos su nombre para intentarlo otra vez mas adelante\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            listado_pdfs_error.append(blob_name)\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "    else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores de analisis de la parte 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos la longitud de la lista con los PDFs que han dado error al ser procesados\n",
    "print(listado_pdfs_error)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos la lista de nuevo procesando los PDFs una segunda vez\n",
    "for pdf_uri in listado_pdfs_error:\n",
    "     blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "     contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "      # Verificar si el contenido del PDF no está vacío\n",
    "     if contenido_pdf.strip():\n",
    "         try:\n",
    "              # Invocar la cadena con el contenido del PDF\n",
    "             res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "              #Agregar el resultado a la lista de resultados\n",
    "             resultados.append(res)\n",
    "              #Imprimir el resultado\n",
    "             print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "         except Exception as e:\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "     else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_ai_annotations_full_3 = pd.DataFrame.from_records(df_resultados['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos cuantas files tienen entradas en blanco y el tipo de variable de cada columna\n",
    "df_ai_annotations_full_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los resultados en un archivo csv\n",
    "df_ai_annotations_full_3.to_csv(\"datasetia_full_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciamos las listas\n",
    "resultados = []\n",
    "listado_pdfs_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos todos los PDFs de la segunda parte\n",
    "for pdf_uri in parte4:\n",
    "    blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "    contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "    # Verificar si el contenido del PDF no está vacío\n",
    "    if contenido_pdf.strip():\n",
    "        try:\n",
    "            # Invocar la cadena con el contenido del PDF\n",
    "            res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "            #Agregar el resultado a la lista de resultados\n",
    "            resultados.append(res)\n",
    "            #Imprimir el resultado\n",
    "            print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "        except Exception as e:\n",
    "            # Si hay algún error al procesar el archivo (a veces pasa), guardamos su nombre para intentarlo otra vez mas adelante\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            listado_pdfs_error.append(blob_name)\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "    else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores de analisis de la parte 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos la longitud de la lista con los PDFs que han dado error al ser procesados\n",
    "print(listado_pdfs_error)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos la lista de nuevo procesando los PDFs una segunda vez\n",
    "for pdf_uri in listado_pdfs_error:\n",
    "     blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "     contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "      # Verificar si el contenido del PDF no está vacío\n",
    "     if contenido_pdf.strip():\n",
    "         try:\n",
    "              # Invocar la cadena con el contenido del PDF\n",
    "             res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "              #Agregar el resultado a la lista de resultados\n",
    "             resultados.append(res)\n",
    "              #Imprimir el resultado\n",
    "             print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "         except Exception as e:\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "     else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_ai_annotations_full_4 = pd.DataFrame.from_records(df_resultados['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos cuantas files tienen entradas en blanco y el tipo de variable de cada columna\n",
    "df_ai_annotations_full_4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los resultados en un archivo csv\n",
    "df_ai_annotations_full_4.to_csv(\"datasetia_full_4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reiniciamos las listas\n",
    "resultados = []\n",
    "listado_pdfs_error = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamos todos los PDFs de la segunda parte\n",
    "for pdf_uri in parte5:\n",
    "    blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "    contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "    # Verificar si el contenido del PDF no está vacío\n",
    "    if contenido_pdf.strip():\n",
    "        try:\n",
    "            # Invocar la cadena con el contenido del PDF\n",
    "            res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "            #Agregar el resultado a la lista de resultados\n",
    "            resultados.append(res)\n",
    "            #Imprimir el resultado\n",
    "            print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "        except Exception as e:\n",
    "            # Si hay algún error al procesar el archivo (a veces pasa), guardamos su nombre para intentarlo otra vez mas adelante\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            listado_pdfs_error.append(blob_name)\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "    else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores de analisis de la parte 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos la longitud de la lista con los PDFs que han dado error al ser procesados\n",
    "print(listado_pdfs_error)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recorremos la lista de nuevo procesando los PDFs una segunda vez\n",
    "for pdf_uri in listado_pdfs_error:\n",
    "     blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "     contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "      # Verificar si el contenido del PDF no está vacío\n",
    "     if contenido_pdf.strip():\n",
    "         try:\n",
    "              # Invocar la cadena con el contenido del PDF\n",
    "             res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "              #Agregar el resultado a la lista de resultados\n",
    "             resultados.append(res)\n",
    "              #Imprimir el resultado\n",
    "             print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "         except Exception as e:\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "     else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df_ai_annotations_full_5 = pd.DataFrame.from_records(df_resultados['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprobamos cuantas files tienen entradas en blanco y el tipo de variable de cada columna\n",
    "df_ai_annotations_full_5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los resultados en un archivo csv\n",
    "df_ai_annotations_full_5.to_csv(\"datasetia_full_5.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
