{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from io import BytesIO\n",
    "from pypdf import PdfReader  # You may need to install pypdf if you haven't already\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "#from langchain.llms import OpenAI\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'xenon-heading-430209-e4-7582f64a7330.json' # Rellenar con el .json correspondiente\n",
    "logging.basicConfig(filename='error_log.txt', level=logging.ERROR, format='%(asctime)s %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_blob_en_memoria(bucket_name, blob_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    pdf_content = blob.download_as_bytes()\n",
    "    return pdf_content\n",
    "\n",
    "def extraer_texto_de_pdf_bytes(pdf_bytes):\n",
    "    pdf_file = BytesIO(pdf_bytes)\n",
    "    reader = PdfReader(pdf_file)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + '\\n'\n",
    "    return text\n",
    "\n",
    "def procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name):\n",
    "    pdf_bytes = leer_blob_en_memoria(bucket_name, blob_name)\n",
    "    content = extraer_texto_de_pdf_bytes(pdf_bytes)\n",
    "    return content\n",
    "\n",
    "def listar_pdfs(bucket_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs()\n",
    "\n",
    "    # Filtra los archivos PDF y guarda sus URLs completas en la lista\n",
    "    listado_pdfs = [f\"gs://{bucket_name}/{blob.name}\" for blob in blobs if blob.name.endswith('.pdf') and not blob.name.startswith('resoluciones/')]\n",
    "    return listado_pdfs\n",
    "\n",
    "def dividir_lista_pdfs(listado_pdfs):\n",
    "    total = len(listado_pdfs)\n",
    "    tamaño_parte = total // 5\n",
    "    \n",
    "    parte1 = listado_pdfs[:tamaño_parte]\n",
    "    parte2 = listado_pdfs[tamaño_parte:2*tamaño_parte]\n",
    "    parte3 = listado_pdfs[2*tamaño_parte:3*tamaño_parte]\n",
    "    parte4 = listado_pdfs[3*tamaño_parte:4*tamaño_parte]\n",
    "    parte5 = listado_pdfs[4*tamaño_parte:]\n",
    "    \n",
    "    return parte1, parte2, parte3, parte4, parte5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'tfm_javi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los esquemas de respuesta\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"numero_expediente\", description=\"Número de Expediente, ejemplo SD2023/0000046\"),\n",
    "    ResponseSchema(name=\"resolucion\", description=\"Una de las siguientes opciones: negada_con_oposicion, negada_sin_oposicion, aprobada_sin_oposicion, aprobada_con_oposición\"),\n",
    "    ResponseSchema(name=\"numero_de_resolución\", description=\"Número entero de la resolución, ejemplo 2195\"),\n",
    "    ResponseSchema(name=\"denominacion\", description=\"Nombre de la empresa que solicita el registro de la marca\"),\n",
    "    ResponseSchema(name=\"vigencia\", description=\"Fecha en que expira la vigencia del registro, o texto si es negada o vencida\"),\n",
    "    ResponseSchema(name=\"titular\", description=\"Titular de la marca que intenta registrar\"),\n",
    "    ResponseSchema(name=\"clase\", description=\"Número o lista de números de la Clasificación Internacional de Niza, por ejemplo [42, 35, 27]\"),\n",
    "    ResponseSchema(name=\"gaceta\", description=\"Número de la gaceta de Propiedad Industrial donde se publica\"),\n",
    "    ResponseSchema(name=\"tipo\", description=\"Tipo de registro que se intenta realizar, por ejemplo Mixta, Nominativa, Figurativa\"),\n",
    "    ResponseSchema(name=\"fecha_solicitud\", description=\"Fecha de presentación de la solicitud\"),\n",
    "    ResponseSchema(name=\"fecha_resolucion\", description=\"Fecha de resolución\"),\n",
    "    ResponseSchema(name=\"nombre_opositor\", description=\"Nombre de la empresa que se opone a la publicación\"),\n",
    "    ResponseSchema(name=\"signo_opositor_opositores\", description=\"Signo o signos de los opositores en conflicto\"),\n",
    "    ResponseSchema(name=\"argumento_oposición\", description=\"Argumentos en los que se basa para oponerse al registro y artículos en los que se apoya\"),\n",
    "    ResponseSchema(name=\"explicacion_argumentos_oposicion\", description=\"Breve resumen y explicación de los argumentos de la oposición\"),\n",
    "    ResponseSchema(name=\"resolucion_organismo\", description=\"Resolución del organismo competente, por ejemplo: 'DENIEGA el registro de la marca PAPELES LA FAVORITA (Mixta)'\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "# Escapar las llaves para evitar la interpretación de variables\n",
    "format_instructions = format_instructions.replace(\"{\", \"{{\").replace(\"}\", \"}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Eres un Experto abogado Colombiano en analizar resoluciones del SIC (Superintendencia de Industria y Comercio de Colombia),en el ámbito de registro de marcas y lemas.\n",
    "quiero que extraigas el numero de Expediente, la resolución del conflicto, el numero de la resolución, el nombre de la marca que intenta registrarse, el titular que intenta registrar la marca, el numero de clase que intenta registrar, \n",
    "el numero de la gaceta en que ha sido publicada, la fecha de solicitud de registro, nombre de la empresa opositora, el titular de la empresa que se opone si aparece, y los argumentos de derecho en los que se apoya el opositor.\n",
    "\"\"\"\n",
    "human_prompt = f\"\"\"Extrae la información indicada en DATOS a partir del TEXTO de la resolución\n",
    "\n",
    "TEXT\n",
    "---\n",
    "\\n\\n{{contenido_pdf}}\n",
    "---\n",
    "\n",
    "DATOS\n",
    "{format_instructions}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    HumanMessagePromptTemplate.from_template(human_prompt),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tu LLM \n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.5-pro-001\"\n",
    "      #verificar la relacion megas tokens  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt, output_parser=output_parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la lista de PDFs\n",
    "listado_pdfs = listar_pdfs(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listado_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parte1, parte2, parte3, parte4, parte5 = dividir_lista_pdfs(listado_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parte5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar una lista para almacenar los resultados\n",
    "resultados = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for pdf_uri in parte5:\n",
    "     blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "     contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "      # Verificar si el contenido del PDF no está vacío\n",
    "     if contenido_pdf.strip():\n",
    "         try:\n",
    "              # Invocar la cadena con el contenido del PDF\n",
    "             res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "              #Agregar el resultado a la lista de resultados\n",
    "             resultados.append(res)\n",
    "              #Imprimir el resultado\n",
    "             print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "         except Exception as e:\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "     else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Errores de analisis\n",
    "realizamos en la terminal cat error_log.txt que nos da el resultado de:\n",
    "\n",
    "error al procesar resoluciones/NCO-SD2022-0073142.pdf\n",
    "\n",
    "error al procesar resoluciones/NCO-SD2022-0113402.pdf\n",
    "\n",
    "error al procesar resoluciones/SD2022-0017210.pdf\n",
    "\n",
    "vamos  a realizar un intento individual con esos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_pdfs_error = (\n",
    "    #f\"gs://{bucket_name}/NCO-SD2018-0088625.pdf\",\n",
    "    #f\"gs://{bucket_name}/NCO-SD2018-0098791.pdf\",\n",
    "    #f\"gs://{bucket_name}/NCO-SD2019-0020998.pdf\",\n",
    "    #f\"gs://{bucket_name}/NCO-SD2019-0025443.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2019-0077987.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2019-0086865.pdf\",\n",
    "    f\"gs://{bucket_name}/NSO-SD2020-0067729.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2020-0070008.pdf\",\n",
    "    f\"gs://{bucket_name}/NSO-SD2020-0072423.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2020-0093067.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2020-0107440.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2021-0001032.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2021-0011099.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2021-0024718.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2021-0045759.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2021-0059591.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2021-0066429.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2021-0085391.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2022-0011807.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2022-0014356.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2022-0028602.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2022-0038932.pdf\",\n",
    "    f\"gs://{bucket_name}/NCO-SD2022-0127271.pdf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listado_pdfs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listado_pdfs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for pdf_uri in listado_pdfs_error:\n",
    "     blob_name = pdf_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "     contenido_pdf = procesar_pdf_desde_gcs_en_memoria(bucket_name, blob_name)\n",
    "    \n",
    "      # Verificar si el contenido del PDF no está vacío\n",
    "     if contenido_pdf.strip():\n",
    "         try:\n",
    "              # Invocar la cadena con el contenido del PDF\n",
    "             res = chain.invoke({\"contenido_pdf\": contenido_pdf})\n",
    "              #Agregar el resultado a la lista de resultados\n",
    "             resultados.append(res)\n",
    "              #Imprimir el resultado\n",
    "             print(f\"Resultado para {blob_name}:\\n{res}\\n\")\n",
    "         except Exception as e:\n",
    "            error_message = f\"Ocurrió un error al procesar {blob_name}: {e}\"\n",
    "            print(error_message)\n",
    "            # Registrar el error en el log\n",
    "            logging.error(error_message)\n",
    "     else:\n",
    "        error_message = f\"El contenido de {blob_name} está vacío o no se pudo extraer texto.\"\n",
    "        print(error_message)\n",
    "        # Registrar el error en el log\n",
    "        logging.error(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiero volver a intentar este registro CSO-SD2022-0105220.pdf\n",
    "\n",
    "Parece que esta vez si que ha procesado bien los tres archivos que diéron error, vamos a construir un df con los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_annotations_full_5 = pd.DataFrame.from_records(df_resultados['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_annotations_full_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_annotations_full_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_annotations[\"argumento_oposición\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ai_annotations_full_5.to_csv(\"datasetia_full_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasetia.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***JDS:*** *veo haciendo una exploración que XING FA es una marca que al parecer ya esta registrada, y que la SIC ha entrado de oficio en un caso (expediente SD2022/0011834) porque entra en conflicto con esa marca, hago una exploración muy basica a ver si es uno de los casos que ya hemos procesado y aparentemete no, es posible que si que este pero habria que normalizarlo a minusculas etc, pero tambien es muy posible que no este al ser solo 419 elementos del total, habria que hacer un merge con la bbdd del sql que nos dieron de sysmarck*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"denominacion\"].str.contains(\"XING FA\", case=False, na=False)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM-mwc0f3M8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
